[
  {
    "prompt_id": 0,
    "prompt": "in football whats the point of wasting the first two plays with a rush - up the middle - not regular rush plays i get those",
    "L": 15,
    "original_message": "011111101001100",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a51\u22a5\u22a5\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 2,
      "undecided_bits": 13,
      "decided_bits": 2,
      "accuracy_percent": 13.333333333333334,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 1,
    "prompt": "Why are different tiers (regular < mid < premium) of gas' prices almost always 10 cents different?",
    "L": 15,
    "original_message": "111100111001010",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 0,
      "undecided_bits": 15,
      "decided_bits": 0,
      "accuracy_percent": 0.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 2,
    "prompt": "Stars and Visibility",
    "L": 15,
    "original_message": "101111110111001",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a51\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 3,
    "prompt": "How do we know all the money the government is getting from bank settlements is going back to the people?",
    "L": 15,
    "original_message": "011010101100110",
    "recovered_message": "\u22a5\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5001\u22a50",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 5,
      "undecided_bits": 10,
      "decided_bits": 5,
      "accuracy_percent": 33.33333333333333,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 4,
    "prompt": "What are good and bad sides of manual and automatic drive gear?",
    "L": 15,
    "original_message": "000100100010010",
    "recovered_message": "\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 5,
    "prompt": "How do muscles grow?",
    "L": 15,
    "original_message": "000010111101001",
    "recovered_message": "\u22a500010\u22a5\u22a5\u22a51\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 6,
      "undecided_bits": 9,
      "decided_bits": 6,
      "accuracy_percent": 40.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 6,
    "prompt": "Why does the water from my kitchen faucet taste different than the water from my bathroom faucet? Doesn't it come from the same place?",
    "L": 15,
    "original_message": "010011001000101",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a50\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 7,
    "prompt": "If dark colours absorb more heat, why does light skin burn easier than dark skin?",
    "L": 15,
    "original_message": "111001101010110",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 0,
      "undecided_bits": 15,
      "decided_bits": 0,
      "accuracy_percent": 0.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 8,
    "prompt": "How the fuck does Facebook know about people I know?!",
    "L": 15,
    "original_message": "010100110101011",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 9,
    "prompt": "Why is chickenpox worse as an adult?",
    "L": 15,
    "original_message": "110001011010001",
    "recovered_message": "\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5\u22a5\u22a50\u22a50\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 3,
      "undecided_bits": 12,
      "decided_bits": 3,
      "accuracy_percent": 20.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 10,
    "prompt": "How do movies not get uploaded online in HD from movie theater employees before their DVD release?",
    "L": 15,
    "original_message": "110000000111010",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 11,
    "prompt": "Can defense attorneys 'throw' a case if they know their clients are guilty?",
    "L": 15,
    "original_message": "011100010110101",
    "recovered_message": "\u22a51\u22a51\u22a5\u22a5\u22a5\u22a5\u22a51\u22a5\u22a51\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 4,
      "undecided_bits": 11,
      "decided_bits": 4,
      "accuracy_percent": 26.666666666666668,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 12,
    "prompt": "why, when intoxicated, does it feel like everything is spinning when you close your eyes but stops spinning when you open them?",
    "L": 15,
    "original_message": "011000010111001",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 0,
      "undecided_bits": 15,
      "decided_bits": 0,
      "accuracy_percent": 0.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 13,
    "prompt": "Why are some fish bones edible, and others are not?",
    "L": 15,
    "original_message": "110100110011111",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a51\u22a5\u22a5\u22a5\u22a5\u22a51\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 2,
      "undecided_bits": 13,
      "decided_bits": 2,
      "accuracy_percent": 13.333333333333334,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 14,
    "prompt": "What's the meaning of the phrase \"I've got a bone to pick with you.\"",
    "L": 15,
    "original_message": "001111110001000",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 15,
    "prompt": "Why can't we just taste candy or Sweets and then spit it out to avoid its unhealthy attributes? What makes us swallow it to get satisfaction?",
    "L": 15,
    "original_message": "111011110101111",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 0,
      "undecided_bits": 15,
      "decided_bits": 0,
      "accuracy_percent": 0.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 16,
    "prompt": "Why are the things that taste the best bad for us?",
    "L": 15,
    "original_message": "110011111000000",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 0,
      "undecided_bits": 15,
      "decided_bits": 0,
      "accuracy_percent": 0.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 17,
    "prompt": "Why do you see weird colors when you press your eyes?",
    "L": 15,
    "original_message": "111101011000111",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 0,
      "undecided_bits": 15,
      "decided_bits": 0,
      "accuracy_percent": 0.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 18,
    "prompt": "If a movie production has $5,000,000 (estimated) Budget, must some of that money go to the actors? or only movie's production quality?",
    "L": 15,
    "original_message": "010011111000011",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a51\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 19,
    "prompt": "What classifies an island as an island? Aren't all continents etc essentially large islands?",
    "L": 15,
    "original_message": "001010111001001",
    "recovered_message": "\u22a5\u22a51\u22a5\u22a5011\u22a5\u22a50\u22a50\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 6,
      "undecided_bits": 9,
      "decided_bits": 6,
      "accuracy_percent": 40.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 20,
    "prompt": "why does wikipedia ask for donations almost every month? do they really need it to not disappear?",
    "L": 15,
    "original_message": "010101001010101",
    "recovered_message": "\u22a5\u22a50\u22a5\u22a5\u22a5\u22a50\u22a5\u22a51\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 3,
      "undecided_bits": 12,
      "decided_bits": 3,
      "accuracy_percent": 20.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 21,
    "prompt": "How does a water purifier jug work and could you put 3rd world ditch water through one and drink safely?",
    "L": 15,
    "original_message": "111010111101011",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a510\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 2,
      "undecided_bits": 13,
      "decided_bits": 2,
      "accuracy_percent": 13.333333333333334,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 22,
    "prompt": "Why people like getting drunk/sloshed/hammered/shit-faced ?",
    "L": 15,
    "original_message": "101101000000101",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 23,
    "prompt": "Why has the Mars Rover Opportunity's Lithium Ion Battery Lasted 11+ Years and the one in My Cell Phone/Laptop/Tablet Dies in Less Than 2?",
    "L": 15,
    "original_message": "101111001100011",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a51\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 24,
    "prompt": "Why is sales tax in the US excluded from the list price?",
    "L": 15,
    "original_message": "101111001010111",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a51\u22a5\u22a50\u22a501\u22a5111",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 7,
      "undecided_bits": 8,
      "decided_bits": 7,
      "accuracy_percent": 46.666666666666664,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 25,
    "prompt": "Why does a beer on tap almost always taste better than it does from a bottle?",
    "L": 15,
    "original_message": "000011001000101",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 0,
      "undecided_bits": 15,
      "decided_bits": 0,
      "accuracy_percent": 0.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 26,
    "prompt": "What is the significance of Jamaican Bobsled team qualifies for the Olympics?",
    "L": 15,
    "original_message": "100001011011111",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 0,
      "undecided_bits": 15,
      "decided_bits": 0,
      "accuracy_percent": 0.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 27,
    "prompt": "Is it possible to build up an immunity to poisons both naturally occurring and man-made?",
    "L": 15,
    "original_message": "001010001110101",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 0,
      "undecided_bits": 15,
      "decided_bits": 0,
      "accuracy_percent": 0.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 28,
    "prompt": "How do devices know the amount of charge left in a battery?",
    "L": 15,
    "original_message": "010110110111110",
    "recovered_message": "\u22a5\u22a5\u22a51\u22a5\u22a5\u22a5\u22a5\u22a5\u22a51\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 2,
      "undecided_bits": 13,
      "decided_bits": 2,
      "accuracy_percent": 13.333333333333334,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 29,
    "prompt": "Why are my muscles sore after jumping in cold water?",
    "L": 15,
    "original_message": "000110001000100",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 0,
      "undecided_bits": 15,
      "decided_bits": 0,
      "accuracy_percent": 0.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 30,
    "prompt": "why do we like watching the same TV show or movie over and over again?",
    "L": 15,
    "original_message": "101111011001101",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 0,
      "undecided_bits": 15,
      "decided_bits": 0,
      "accuracy_percent": 0.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 31,
    "prompt": "why do the French have an abstain vote instead of people physically restraining from voting. [Other]",
    "L": 15,
    "original_message": "111100001101000",
    "recovered_message": "\u22a51\u22a5\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 2,
      "undecided_bits": 13,
      "decided_bits": 2,
      "accuracy_percent": 13.333333333333334,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 32,
    "prompt": "Why The Beatles broke up?",
    "L": 15,
    "original_message": "100110000001011",
    "recovered_message": "1\u22a5011000\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 8,
      "undecided_bits": 7,
      "decided_bits": 8,
      "accuracy_percent": 53.333333333333336,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 33,
    "prompt": "- Why do phones not require cooling vents but other small appliances do?",
    "L": 15,
    "original_message": "010100100010011",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 34,
    "prompt": "Why are oil prices so shockingly low?",
    "L": 15,
    "original_message": "110010010010100",
    "recovered_message": "\u22a51\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a51\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 2,
      "undecided_bits": 13,
      "decided_bits": 2,
      "accuracy_percent": 13.333333333333334,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 35,
    "prompt": "If the inside of my microwave is made of metal, why is it bad to put metallic objects in it?",
    "L": 15,
    "original_message": "011011100100100",
    "recovered_message": "0\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a510\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 3,
      "undecided_bits": 12,
      "decided_bits": 3,
      "accuracy_percent": 20.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 36,
    "prompt": "Why do we lack the instincts our ancestors had, e.g. telling you which foods are poisonous",
    "L": 15,
    "original_message": "011010011100011",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 37,
    "prompt": "Why do we wake up early when we don't have to but tend to wake up late when we need to be up?",
    "L": 15,
    "original_message": "100001111011101",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a51",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 38,
    "prompt": "Why do tech/software companies stay in the US when they are demanded to include backdoors by the US government? Can't tech companies just develop and release their products overseas, out of reach of the US government's influence?",
    "L": 15,
    "original_message": "110001011011101",
    "recovered_message": "1\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5\u22a50111\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 6,
      "undecided_bits": 9,
      "decided_bits": 6,
      "accuracy_percent": 40.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 39,
    "prompt": "with such an important vote like appointing a supreme court nomine, why is the senate floor so empty?",
    "L": 15,
    "original_message": "000011001010001",
    "recovered_message": "00\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 2,
      "undecided_bits": 13,
      "decided_bits": 2,
      "accuracy_percent": 13.333333333333334,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 40,
    "prompt": "If you put tires on your car that are larger than the ones from the factory, would you actually be going slower than the reading on your speedometer?",
    "L": 15,
    "original_message": "011000100011001",
    "recovered_message": "\u22a5\u22a51\u22a5\u22a501\u22a5\u22a5\u22a5\u22a5\u22a5\u22a50\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 4,
      "undecided_bits": 11,
      "decided_bits": 4,
      "accuracy_percent": 26.666666666666668,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 41,
    "prompt": "How does bugspray kills bugs?",
    "L": 15,
    "original_message": "011110001110011",
    "recovered_message": "\u22a51\u22a5\u22a5\u22a5\u22a50\u22a5\u22a5\u22a510\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 4,
      "undecided_bits": 11,
      "decided_bits": 4,
      "accuracy_percent": 26.666666666666668,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 42,
    "prompt": "If a computer has a GPU, why would reducing GUI effects impact performance?",
    "L": 15,
    "original_message": "100000100001010",
    "recovered_message": "1\u22a5\u22a5\u22a5\u22a50\u22a5\u22a50\u22a50\u22a5\u22a510",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 6,
      "undecided_bits": 9,
      "decided_bits": 6,
      "accuracy_percent": 40.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 43,
    "prompt": "What happens if you don't pay your US Federal income tax?",
    "L": 15,
    "original_message": "100101011010011",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a51\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 44,
    "prompt": "Why does my employer require a voided personal check in order to setup direct deposit?",
    "L": 15,
    "original_message": "100010101010100",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 45,
    "prompt": "Why are the insides of Ovens Dark and Not Metallic or Mirror Like?",
    "L": 15,
    "original_message": "011011100000111",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 0,
      "undecided_bits": 15,
      "decided_bits": 0,
      "accuracy_percent": 0.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 46,
    "prompt": "Why does metal react so violently when microwaved?",
    "L": 15,
    "original_message": "100110101000100",
    "recovered_message": "10\u22a5\u22a51\u22a5\u22a5\u22a5\u22a5\u22a5\u22a50\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 4,
      "undecided_bits": 11,
      "decided_bits": 4,
      "accuracy_percent": 26.666666666666668,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 47,
    "prompt": "How did the American accent come about?",
    "L": 15,
    "original_message": "111111001110100",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 0,
      "undecided_bits": 15,
      "decided_bits": 0,
      "accuracy_percent": 0.0,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 48,
    "prompt": "Why do The Miranda Rights state that anything you say can \"and will\" be used against you. If something's not incriminating why would it be used against you? Why would cops be forced to admit this up front?",
    "L": 15,
    "original_message": "001101110011001",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a51\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  },
  {
    "prompt_id": 49,
    "prompt": "Why is it when you rewind VHS tapes they lose their quality over time?",
    "L": 15,
    "original_message": "000101111000110",
    "recovered_message": "\u22a5\u22a5\u22a5\u22a50\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5\u22a5",
    "accuracy_metrics": {
      "total_bits": 15,
      "correct_bits": 1,
      "undecided_bits": 14,
      "decided_bits": 1,
      "accuracy_percent": 6.666666666666667,
      "exact_match": false
    },
    "parameters": {
      "delta": 2.5,
      "entropy_threshold": 4.0,
      "hashing_context": 5,
      "z_threshold": 4.0,
      "max_new_tokens": 512
    }
  }
]